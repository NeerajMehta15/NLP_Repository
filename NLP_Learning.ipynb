{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeerajMehta15/NLP_Repository/blob/main/NLP_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9P4fSgop3oT7",
        "outputId": "e2ab21d7-8f3d-40e4-8f7d-00dd4375723a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Collecting readability-lxml\n",
            "  Downloading readability_lxml-0.8.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (5.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (5.3.0)\n",
            "Collecting cssselect (from readability-lxml)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading readability_lxml-0.8.1-py3-none-any.whl (20 kB)\n",
            "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: cssselect, readability-lxml\n",
            "Successfully installed cssselect-1.2.0 readability-lxml-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!pip install nltk\n",
        "!pip install readability-lxml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk"
      ],
      "metadata": {
        "id": "GgWxvWob3v_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = \"\"\"I am seeking opportunities to work on advanced data science and machine learning projects that align with my career goals.\n",
        "I aim to expand my expertise in deep learning and large language models, which are areas of personal interest and growth.\n",
        "I want to take on more challenging roles that allow me to make a greater impact in the field of analytics and AI.\n",
        "I am looking for a role that offers broader exposure to cutting-edge technologies and innovative projects.\n",
        "I aspire to be part of an organization where I can contribute to and learn from a dynamic team of professionals.\n",
        "My goal is to secure a position with greater responsibilities and opportunities for leadership.\n",
        "I am focused on career advancement and aligning my work with long-term professional #aspirations.\n",
        "I want to work in an environment that fosters continuous learning and skill development.\n",
        "I am seeking a role that offers better alignment with my personal values and career vision.\n",
        "My decision is driven by the desire to grow professionally and make a significant contribution in a fast-evolving #industry.\"\"\"\n"
      ],
      "metadata": {
        "id": "7-m9CvvF4FZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count number of characters\n",
        "def word_count(doc):\n",
        "  words = doc.split()\n",
        "  return len(words)\n",
        "\n",
        "num = word_count(docs)\n",
        "print(f\"Total number of words in this doc is {num}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6wMgGV24afS",
        "outputId": "abd13323-7716-4076-fe2d-26ff40ca7922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words in this doc is 178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns number of hashtag\n",
        "def hashtag_count(doc):\n",
        "  words = doc.split()\n",
        "  hashtag = [word for word in words if word.startswith(\"#\")]\n",
        "  return hashtag\n",
        "\n",
        "hastag_count = hashtag_count(docs)\n",
        "print((f\"Number of hastag in this doc is {hastag_count}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeeUaNg45Caw",
        "outputId": "b6bb38fe-647b-45d6-f507-3760b28dc464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of hastag in this doc is ['#aspirations.', '#industry.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from readability import Readability\n",
        "# Calculate readability scores\n",
        "nltk.download('punkt')\n",
        "readability_scores = Readability(text)\n",
        "gf = readability_scores.gunning_fog()\n",
        "print(gf.score)\n"
      ],
      "metadata": {
        "id": "OgXXetSWcUP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization and lemmetization\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "dox = nlp(docs)\n",
        "stopwords = [token.text for token in dox]\n",
        "print(stopwords)\n",
        "print(len(stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKQaNQEucWQp",
        "outputId": "a6a8b270-c850-4730-eb70-402065e864e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'seeking', 'opportunities', 'to', 'work', 'on', 'advanced', 'data', 'science', 'and', 'machine', 'learning', 'projects', 'that', 'align', 'with', 'my', 'career', 'goals', '.', '\\n', 'I', 'aim', 'to', 'expand', 'my', 'expertise', 'in', 'deep', 'learning', 'and', 'large', 'language', 'models', ',', 'which', 'are', 'areas', 'of', 'personal', 'interest', 'and', 'growth', '.', '\\n', 'I', 'want', 'to', 'take', 'on', 'more', 'challenging', 'roles', 'that', 'allow', 'me', 'to', 'make', 'a', 'greater', 'impact', 'in', 'the', 'field', 'of', 'analytics', 'and', 'AI', '.', '\\n', 'I', 'am', 'looking', 'for', 'a', 'role', 'that', 'offers', 'broader', 'exposure', 'to', 'cutting', '-', 'edge', 'technologies', 'and', 'innovative', 'projects', '.', '\\n', 'I', 'aspire', 'to', 'be', 'part', 'of', 'an', 'organization', 'where', 'I', 'can', 'contribute', 'to', 'and', 'learn', 'from', 'a', 'dynamic', 'team', 'of', 'professionals', '.', '\\n', 'My', 'goal', 'is', 'to', 'secure', 'a', 'position', 'with', 'greater', 'responsibilities', 'and', 'opportunities', 'for', 'leadership', '.', '\\n', 'I', 'am', 'focused', 'on', 'career', 'advancement', 'and', 'aligning', 'my', 'work', 'with', 'long', '-', 'term', 'professional', '#', 'aspirations', '.', '\\n', 'I', 'want', 'to', 'work', 'in', 'an', 'environment', 'that', 'fosters', 'continuous', 'learning', 'and', 'skill', 'development', '.', '\\n', 'I', 'am', 'seeking', 'a', 'role', 'that', 'offers', 'better', 'alignment', 'with', 'my', 'personal', 'values', 'and', 'career', 'vision', '.', '\\n', 'My', 'decision', 'is', 'driven', 'by', 'the', 'desire', 'to', 'grow', 'professionally', 'and', 'make', 'a', 'significant', 'contribution', 'in', 'a', 'fast', '-', 'evolving', '#', 'industry', '.']\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization and lemmetization\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "docx = nlp(docs)\n",
        "lemma_list = []\n",
        "lemma_list = [token.lemma_ for token in docx]\n",
        "print(lemma_list)\n",
        "print(len(stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea3u5_UXdp-1",
        "outputId": "abe1d867-d8c3-49b6-e1e5-43b870fcd60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'be', 'seek', 'opportunity', 'to', 'work', 'on', 'advanced', 'datum', 'science', 'and', 'machine', 'learning', 'project', 'that', 'align', 'with', 'my', 'career', 'goal', '.', '\\n', 'I', 'aim', 'to', 'expand', 'my', 'expertise', 'in', 'deep', 'learning', 'and', 'large', 'language', 'model', ',', 'which', 'be', 'area', 'of', 'personal', 'interest', 'and', 'growth', '.', '\\n', 'I', 'want', 'to', 'take', 'on', 'more', 'challenging', 'role', 'that', 'allow', 'I', 'to', 'make', 'a', 'great', 'impact', 'in', 'the', 'field', 'of', 'analytic', 'and', 'AI', '.', '\\n', 'I', 'be', 'look', 'for', 'a', 'role', 'that', 'offer', 'broad', 'exposure', 'to', 'cut', '-', 'edge', 'technology', 'and', 'innovative', 'project', '.', '\\n', 'I', 'aspire', 'to', 'be', 'part', 'of', 'an', 'organization', 'where', 'I', 'can', 'contribute', 'to', 'and', 'learn', 'from', 'a', 'dynamic', 'team', 'of', 'professional', '.', '\\n', 'my', 'goal', 'be', 'to', 'secure', 'a', 'position', 'with', 'great', 'responsibility', 'and', 'opportunity', 'for', 'leadership', '.', '\\n', 'I', 'be', 'focus', 'on', 'career', 'advancement', 'and', 'align', 'my', 'work', 'with', 'long', '-', 'term', 'professional', '#', 'aspiration', '.', '\\n', 'I', 'want', 'to', 'work', 'in', 'an', 'environment', 'that', 'foster', 'continuous', 'learning', 'and', 'skill', 'development', '.', '\\n', 'I', 'be', 'seek', 'a', 'role', 'that', 'offer', 'well', 'alignment', 'with', 'my', 'personal', 'value', 'and', 'career', 'vision', '.', '\\n', 'my', 'decision', 'be', 'drive', 'by', 'the', 'desire', 'to', 'grow', 'professionally', 'and', 'make', 'a', 'significant', 'contribution', 'in', 'a', 'fast', '-', 'evolve', '#', 'industry', '.']\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove tokens that are not alphabetic\n",
        "a_lemmas = [lemma for lemma in lemma_list if lemma.isalpha() or lemma == '-PRON-']\n",
        "# Print string after text cleaning\n",
        "print(' '. join(a_lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X59Lg9veUPM",
        "outputId": "88a3144f-a99f-49e5-c819-95e24022e6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I be seek opportunity to work on advanced datum science and machine learning project that align with my career goal I aim to expand my expertise in deep learning and large language model which be area of personal interest and growth I want to take on more challenging role that allow I to make a great impact in the field of analytic and AI I be look for a role that offer broad exposure to cut edge technology and innovative project I aspire to be part of an organization where I can contribute to and learn from a dynamic team of professional my goal be to secure a position with great responsibility and opportunity for leadership I be focus on career advancement and align my work with long term professional aspiration I want to work in an environment that foster continuous learning and skill development I be seek a role that offer well alignment with my personal value and career vision my decision be drive by the desire to grow professionally and make a significant contribution in a fast evolve industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of stopwords\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "#Remove stopwords\n",
        "clean = [lemma for lemma in lemma_list if lemma not in stopwords or lemma == '-PRON-']\n",
        "print(' '.join(clean))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKLQKDbbepMk",
        "outputId": "d7d4660f-7686-48e7-84ce-769d2a93f4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I seek opportunity work advanced datum science machine learning project align career goal . \n",
            " I aim expand expertise deep learning large language model , area personal interest growth . \n",
            " I want challenging role allow I great impact field analytic AI . \n",
            " I look role offer broad exposure cut - edge technology innovative project . \n",
            " I aspire organization I contribute learn dynamic team professional . \n",
            " goal secure position great responsibility opportunity leadership . \n",
            " I focus career advancement align work long - term professional # aspiration . \n",
            " I want work environment foster continuous learning skill development . \n",
            " I seek role offer alignment personal value career vision . \n",
            " decision drive desire grow professionally significant contribution fast - evolve # industry .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POS Tagging\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "dox = nlp(docs)\n",
        "tagged = [(token.text , token.pos_) for token in dox]\n",
        "print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ5b4zXDfKnt",
        "outputId": "a7fca564-b6db-486f-d300-ec901a8432d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRON'), ('am', 'AUX'), ('seeking', 'VERB'), ('opportunities', 'NOUN'), ('to', 'PART'), ('work', 'VERB'), ('on', 'ADP'), ('advanced', 'ADJ'), ('data', 'NOUN'), ('science', 'NOUN'), ('and', 'CCONJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('projects', 'NOUN'), ('that', 'PRON'), ('align', 'VERB'), ('with', 'ADP'), ('my', 'PRON'), ('career', 'NOUN'), ('goals', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('aim', 'VERB'), ('to', 'PART'), ('expand', 'VERB'), ('my', 'PRON'), ('expertise', 'NOUN'), ('in', 'ADP'), ('deep', 'ADJ'), ('learning', 'NOUN'), ('and', 'CCONJ'), ('large', 'ADJ'), ('language', 'NOUN'), ('models', 'NOUN'), (',', 'PUNCT'), ('which', 'PRON'), ('are', 'AUX'), ('areas', 'NOUN'), ('of', 'ADP'), ('personal', 'ADJ'), ('interest', 'NOUN'), ('and', 'CCONJ'), ('growth', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('take', 'VERB'), ('on', 'ADP'), ('more', 'ADJ'), ('challenging', 'ADJ'), ('roles', 'NOUN'), ('that', 'PRON'), ('allow', 'VERB'), ('me', 'PRON'), ('to', 'PART'), ('make', 'VERB'), ('a', 'DET'), ('greater', 'ADJ'), ('impact', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('field', 'NOUN'), ('of', 'ADP'), ('analytics', 'NOUN'), ('and', 'CCONJ'), ('AI', 'PROPN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('am', 'AUX'), ('looking', 'VERB'), ('for', 'ADP'), ('a', 'DET'), ('role', 'NOUN'), ('that', 'PRON'), ('offers', 'VERB'), ('broader', 'ADJ'), ('exposure', 'NOUN'), ('to', 'ADP'), ('cutting', 'VERB'), ('-', 'PUNCT'), ('edge', 'NOUN'), ('technologies', 'NOUN'), ('and', 'CCONJ'), ('innovative', 'ADJ'), ('projects', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('aspire', 'VERB'), ('to', 'PART'), ('be', 'AUX'), ('part', 'NOUN'), ('of', 'ADP'), ('an', 'DET'), ('organization', 'NOUN'), ('where', 'SCONJ'), ('I', 'PRON'), ('can', 'AUX'), ('contribute', 'VERB'), ('to', 'ADP'), ('and', 'CCONJ'), ('learn', 'VERB'), ('from', 'ADP'), ('a', 'DET'), ('dynamic', 'ADJ'), ('team', 'NOUN'), ('of', 'ADP'), ('professionals', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('My', 'PRON'), ('goal', 'NOUN'), ('is', 'AUX'), ('to', 'PART'), ('secure', 'VERB'), ('a', 'DET'), ('position', 'NOUN'), ('with', 'ADP'), ('greater', 'ADJ'), ('responsibilities', 'NOUN'), ('and', 'CCONJ'), ('opportunities', 'NOUN'), ('for', 'ADP'), ('leadership', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('am', 'AUX'), ('focused', 'VERB'), ('on', 'ADP'), ('career', 'NOUN'), ('advancement', 'NOUN'), ('and', 'CCONJ'), ('aligning', 'VERB'), ('my', 'PRON'), ('work', 'NOUN'), ('with', 'ADP'), ('long', 'ADJ'), ('-', 'PUNCT'), ('term', 'NOUN'), ('professional', 'ADJ'), ('#', 'NOUN'), ('aspirations', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('work', 'VERB'), ('in', 'ADP'), ('an', 'DET'), ('environment', 'NOUN'), ('that', 'PRON'), ('fosters', 'VERB'), ('continuous', 'ADJ'), ('learning', 'NOUN'), ('and', 'CCONJ'), ('skill', 'NOUN'), ('development', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('I', 'PRON'), ('am', 'AUX'), ('seeking', 'VERB'), ('a', 'DET'), ('role', 'NOUN'), ('that', 'PRON'), ('offers', 'VERB'), ('better', 'ADJ'), ('alignment', 'NOUN'), ('with', 'ADP'), ('my', 'PRON'), ('personal', 'ADJ'), ('values', 'NOUN'), ('and', 'CCONJ'), ('career', 'NOUN'), ('vision', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('My', 'PRON'), ('decision', 'NOUN'), ('is', 'AUX'), ('driven', 'VERB'), ('by', 'ADP'), ('the', 'DET'), ('desire', 'NOUN'), ('to', 'PART'), ('grow', 'VERB'), ('professionally', 'ADV'), ('and', 'CCONJ'), ('make', 'VERB'), ('a', 'DET'), ('significant', 'ADJ'), ('contribution', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('fast', 'ADV'), ('-', 'PUNCT'), ('evolving', 'VERB'), ('#', 'NOUN'), ('industry', 'NOUN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POS Tagging\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "dox = nlp(docs)\n",
        "ne = [(ent.text, ent.label_) for ent in dox.ents]\n",
        "print(ne)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h_98F2Qf1Yp",
        "outputId": "6f17a353-9a40-4d95-9004-79bee25fd9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('AI', 'ORG'), ('#', 'CARDINAL')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_list = [\n",
        "    \"I am seeking opportunities to work on advanced data science and machine learning projects that align with my career goals.\",\n",
        "    \"I aim to expand my expertise in deep learning and large language models, which are areas of personal interest and growth.\",\n",
        "    \"I want to take on more challenging roles that allow me to make a greater impact in the field of analytics and AI.\",\n",
        "    \"I am looking for a role that offers broader exposure to cutting-edge technologies and innovative projects.\",\n",
        "    \"I aspire to be part of an organization where I can contribute to and learn from a dynamic team of professionals.\",\n",
        "    \"My goal is to secure a position with greater responsibilities and opportunities for leadership.\",\n",
        "    \"I am focused on career advancement and aligning my work with long-term professional aspirations.\",\n",
        "    \"I want to work in an environment that fosters continuous learning and skill development.\",\n",
        "    \"I am seeking a role that offers better alignment with my personal values and career vision.\",\n",
        "    \"My decision is driven by the desire to grow professionally and make a significant contribution in a fast-evolving industry.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "sTDp8VobhN2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using count vectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorize = CountVectorizer()\n",
        "bow_matrix = vectorize.fit_transform(doc_list)\n",
        "print(bow_matrix)\n",
        "\n",
        "# Display the sparse matrix\n",
        "print(\"Sparse Matrix:\\n\", bow_matrix)\n",
        "print(\"\\nDense Matrix:\\n\", bow_matrix.toarray())\n",
        "print(\"\\nFeature Names:\\n\", vectorize.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0gTRZyQsgVx4",
        "outputId": "791a292b-daf7-47c6-eb5f-1c500edd9d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 8)\t1\n",
            "  (0, 87)\t1\n",
            "  (0, 73)\t1\n",
            "  (0, 96)\t1\n",
            "  (0, 103)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 85)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 64)\t1\n",
            "  (0, 61)\t1\n",
            "  (0, 81)\t1\n",
            "  (0, 94)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 102)\t1\n",
            "  (0, 69)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 47)\t1\n",
            "  (1, 96)\t1\n",
            "  (1, 11)\t2\n",
            "  (1, 61)\t1\n",
            "  (1, 69)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 37)\t1\n",
            "  :\t:\n",
            "  (8, 76)\t1\n",
            "  (8, 83)\t1\n",
            "  (8, 71)\t1\n",
            "  (8, 17)\t1\n",
            "  (8, 6)\t1\n",
            "  (8, 97)\t1\n",
            "  (8, 98)\t1\n",
            "  (9, 96)\t1\n",
            "  (9, 11)\t1\n",
            "  (9, 69)\t1\n",
            "  (9, 52)\t1\n",
            "  (9, 65)\t1\n",
            "  (9, 95)\t1\n",
            "  (9, 56)\t1\n",
            "  (9, 28)\t1\n",
            "  (9, 32)\t1\n",
            "  (9, 19)\t1\n",
            "  (9, 30)\t1\n",
            "  (9, 49)\t1\n",
            "  (9, 79)\t1\n",
            "  (9, 88)\t1\n",
            "  (9, 25)\t1\n",
            "  (9, 40)\t1\n",
            "  (9, 36)\t1\n",
            "  (9, 53)\t1\n",
            "Sparse Matrix:\n",
            "   (0, 8)\t1\n",
            "  (0, 87)\t1\n",
            "  (0, 73)\t1\n",
            "  (0, 96)\t1\n",
            "  (0, 103)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 85)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 64)\t1\n",
            "  (0, 61)\t1\n",
            "  (0, 81)\t1\n",
            "  (0, 94)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 102)\t1\n",
            "  (0, 69)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 47)\t1\n",
            "  (1, 96)\t1\n",
            "  (1, 11)\t2\n",
            "  (1, 61)\t1\n",
            "  (1, 69)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 37)\t1\n",
            "  :\t:\n",
            "  (8, 76)\t1\n",
            "  (8, 83)\t1\n",
            "  (8, 71)\t1\n",
            "  (8, 17)\t1\n",
            "  (8, 6)\t1\n",
            "  (8, 97)\t1\n",
            "  (8, 98)\t1\n",
            "  (9, 96)\t1\n",
            "  (9, 11)\t1\n",
            "  (9, 69)\t1\n",
            "  (9, 52)\t1\n",
            "  (9, 65)\t1\n",
            "  (9, 95)\t1\n",
            "  (9, 56)\t1\n",
            "  (9, 28)\t1\n",
            "  (9, 32)\t1\n",
            "  (9, 19)\t1\n",
            "  (9, 30)\t1\n",
            "  (9, 49)\t1\n",
            "  (9, 79)\t1\n",
            "  (9, 88)\t1\n",
            "  (9, 25)\t1\n",
            "  (9, 40)\t1\n",
            "  (9, 36)\t1\n",
            "  (9, 53)\t1\n",
            "\n",
            "Dense Matrix:\n",
            " [[1 0 0 ... 0 1 1]\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Feature Names:\n",
            " ['advanced' 'advancement' 'ai' 'aim' 'align' 'aligning' 'alignment'\n",
            " 'allow' 'am' 'an' 'analytics' 'and' 'are' 'areas' 'aspirations' 'aspire'\n",
            " 'be' 'better' 'broader' 'by' 'can' 'career' 'challenging' 'continuous'\n",
            " 'contribute' 'contribution' 'cutting' 'data' 'decision' 'deep' 'desire'\n",
            " 'development' 'driven' 'dynamic' 'edge' 'environment' 'evolving' 'expand'\n",
            " 'expertise' 'exposure' 'fast' 'field' 'focused' 'for' 'fosters' 'from'\n",
            " 'goal' 'goals' 'greater' 'grow' 'growth' 'impact' 'in' 'industry'\n",
            " 'innovative' 'interest' 'is' 'language' 'large' 'leadership' 'learn'\n",
            " 'learning' 'long' 'looking' 'machine' 'make' 'me' 'models' 'more' 'my'\n",
            " 'of' 'offers' 'on' 'opportunities' 'organization' 'part' 'personal'\n",
            " 'position' 'professional' 'professionally' 'professionals' 'projects'\n",
            " 'responsibilities' 'role' 'roles' 'science' 'secure' 'seeking'\n",
            " 'significant' 'skill' 'take' 'team' 'technologies' 'term' 'that' 'the'\n",
            " 'to' 'values' 'vision' 'want' 'where' 'which' 'with' 'work']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Developing n-gram models\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorize = CountVectorizer(ngram_range=(2,5))\n",
        "bow_matrix = vectorize.fit_transform(doc_list)\n",
        "print(bow_matrix)\n",
        "\n",
        "# Display the sparse matrix\n",
        "print(\"Sparse Matrix:\\n\", bow_matrix)\n",
        "print(\"\\nDense Matrix:\\n\", bow_matrix.toarray())\n",
        "print(\"\\nFeature Names:\\n\", vectorize.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uk8aOz5ZhXdU",
        "outputId": "88017e5d-bf3c-48b3-898a-8988af2fdc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 36)\t1\n",
            "  (0, 418)\t1\n",
            "  (0, 364)\t1\n",
            "  (0, 501)\t1\n",
            "  (0, 544)\t1\n",
            "  (0, 350)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 142)\t1\n",
            "  (0, 410)\t1\n",
            "  (0, 71)\t1\n",
            "  (0, 284)\t1\n",
            "  (0, 273)\t1\n",
            "  (0, 392)\t1\n",
            "  (0, 442)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 534)\t1\n",
            "  (0, 308)\t1\n",
            "  (0, 120)\t1\n",
            "  (0, 37)\t1\n",
            "  (0, 419)\t1\n",
            "  (0, 365)\t1\n",
            "  (0, 505)\t1\n",
            "  (0, 545)\t1\n",
            "  (0, 351)\t1\n",
            "  (0, 1)\t1\n",
            "  :\t:\n",
            "  (9, 110)\t1\n",
            "  (9, 463)\t1\n",
            "  (9, 156)\t1\n",
            "  (9, 487)\t1\n",
            "  (9, 223)\t1\n",
            "  (9, 390)\t1\n",
            "  (9, 77)\t1\n",
            "  (9, 294)\t1\n",
            "  (9, 428)\t1\n",
            "  (9, 136)\t1\n",
            "  (9, 239)\t1\n",
            "  (9, 313)\t1\n",
            "  (9, 149)\t1\n",
            "  (9, 250)\t1\n",
            "  (9, 161)\t1\n",
            "  (9, 111)\t1\n",
            "  (9, 464)\t1\n",
            "  (9, 157)\t1\n",
            "  (9, 488)\t1\n",
            "  (9, 224)\t1\n",
            "  (9, 391)\t1\n",
            "  (9, 78)\t1\n",
            "  (9, 295)\t1\n",
            "  (9, 429)\t1\n",
            "  (9, 137)\t1\n",
            "Sparse Matrix:\n",
            "   (0, 36)\t1\n",
            "  (0, 418)\t1\n",
            "  (0, 364)\t1\n",
            "  (0, 501)\t1\n",
            "  (0, 544)\t1\n",
            "  (0, 350)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 142)\t1\n",
            "  (0, 410)\t1\n",
            "  (0, 71)\t1\n",
            "  (0, 284)\t1\n",
            "  (0, 273)\t1\n",
            "  (0, 392)\t1\n",
            "  (0, 442)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 534)\t1\n",
            "  (0, 308)\t1\n",
            "  (0, 120)\t1\n",
            "  (0, 37)\t1\n",
            "  (0, 419)\t1\n",
            "  (0, 365)\t1\n",
            "  (0, 505)\t1\n",
            "  (0, 545)\t1\n",
            "  (0, 351)\t1\n",
            "  (0, 1)\t1\n",
            "  :\t:\n",
            "  (9, 110)\t1\n",
            "  (9, 463)\t1\n",
            "  (9, 156)\t1\n",
            "  (9, 487)\t1\n",
            "  (9, 223)\t1\n",
            "  (9, 390)\t1\n",
            "  (9, 77)\t1\n",
            "  (9, 294)\t1\n",
            "  (9, 428)\t1\n",
            "  (9, 136)\t1\n",
            "  (9, 239)\t1\n",
            "  (9, 313)\t1\n",
            "  (9, 149)\t1\n",
            "  (9, 250)\t1\n",
            "  (9, 161)\t1\n",
            "  (9, 111)\t1\n",
            "  (9, 464)\t1\n",
            "  (9, 157)\t1\n",
            "  (9, 488)\t1\n",
            "  (9, 224)\t1\n",
            "  (9, 391)\t1\n",
            "  (9, 78)\t1\n",
            "  (9, 295)\t1\n",
            "  (9, 429)\t1\n",
            "  (9, 137)\t1\n",
            "\n",
            "Dense Matrix:\n",
            " [[1 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Feature Names:\n",
            " ['advanced data' 'advanced data science' 'advanced data science and'\n",
            " 'advanced data science and machine' 'advancement and'\n",
            " 'advancement and aligning' 'advancement and aligning my'\n",
            " 'advancement and aligning my work' 'aim to' 'aim to expand'\n",
            " 'aim to expand my' 'aim to expand my expertise' 'align with'\n",
            " 'align with my' 'align with my career' 'align with my career goals'\n",
            " 'aligning my' 'aligning my work' 'aligning my work with'\n",
            " 'aligning my work with long' 'alignment with' 'alignment with my'\n",
            " 'alignment with my personal' 'alignment with my personal values'\n",
            " 'allow me' 'allow me to' 'allow me to make' 'allow me to make greater'\n",
            " 'am focused' 'am focused on' 'am focused on career'\n",
            " 'am focused on career advancement' 'am looking' 'am looking for'\n",
            " 'am looking for role' 'am looking for role that' 'am seeking'\n",
            " 'am seeking opportunities' 'am seeking opportunities to'\n",
            " 'am seeking opportunities to work' 'am seeking role'\n",
            " 'am seeking role that' 'am seeking role that offers' 'an environment'\n",
            " 'an environment that' 'an environment that fosters'\n",
            " 'an environment that fosters continuous' 'an organization'\n",
            " 'an organization where' 'an organization where can'\n",
            " 'an organization where can contribute' 'analytics and' 'analytics and ai'\n",
            " 'and ai' 'and aligning' 'and aligning my' 'and aligning my work'\n",
            " 'and aligning my work with' 'and career' 'and career vision' 'and growth'\n",
            " 'and innovative' 'and innovative projects' 'and large'\n",
            " 'and large language' 'and large language models'\n",
            " 'and large language models which' 'and learn' 'and learn from'\n",
            " 'and learn from dynamic' 'and learn from dynamic team' 'and machine'\n",
            " 'and machine learning' 'and machine learning projects'\n",
            " 'and machine learning projects that' 'and make' 'and make significant'\n",
            " 'and make significant contribution'\n",
            " 'and make significant contribution in' 'and opportunities'\n",
            " 'and opportunities for' 'and opportunities for leadership' 'and skill'\n",
            " 'and skill development' 'are areas' 'are areas of'\n",
            " 'are areas of personal' 'are areas of personal interest' 'areas of'\n",
            " 'areas of personal' 'areas of personal interest'\n",
            " 'areas of personal interest and' 'aspire to' 'aspire to be'\n",
            " 'aspire to be part' 'aspire to be part of' 'be part' 'be part of'\n",
            " 'be part of an' 'be part of an organization' 'better alignment'\n",
            " 'better alignment with' 'better alignment with my'\n",
            " 'better alignment with my personal' 'broader exposure'\n",
            " 'broader exposure to' 'broader exposure to cutting'\n",
            " 'broader exposure to cutting edge' 'by the' 'by the desire'\n",
            " 'by the desire to' 'by the desire to grow' 'can contribute'\n",
            " 'can contribute to' 'can contribute to and' 'can contribute to and learn'\n",
            " 'career advancement' 'career advancement and'\n",
            " 'career advancement and aligning' 'career advancement and aligning my'\n",
            " 'career goals' 'career vision' 'challenging roles'\n",
            " 'challenging roles that' 'challenging roles that allow'\n",
            " 'challenging roles that allow me' 'continuous learning'\n",
            " 'continuous learning and' 'continuous learning and skill'\n",
            " 'continuous learning and skill development' 'contribute to'\n",
            " 'contribute to and' 'contribute to and learn'\n",
            " 'contribute to and learn from' 'contribution in' 'contribution in fast'\n",
            " 'contribution in fast evolving' 'contribution in fast evolving industry'\n",
            " 'cutting edge' 'cutting edge technologies'\n",
            " 'cutting edge technologies and'\n",
            " 'cutting edge technologies and innovative' 'data science'\n",
            " 'data science and' 'data science and machine'\n",
            " 'data science and machine learning' 'decision is' 'decision is driven'\n",
            " 'decision is driven by' 'decision is driven by the' 'deep learning'\n",
            " 'deep learning and' 'deep learning and large'\n",
            " 'deep learning and large language' 'desire to' 'desire to grow'\n",
            " 'desire to grow professionally' 'desire to grow professionally and'\n",
            " 'driven by' 'driven by the' 'driven by the desire'\n",
            " 'driven by the desire to' 'dynamic team' 'dynamic team of'\n",
            " 'dynamic team of professionals' 'edge technologies'\n",
            " 'edge technologies and' 'edge technologies and innovative'\n",
            " 'edge technologies and innovative projects' 'environment that'\n",
            " 'environment that fosters' 'environment that fosters continuous'\n",
            " 'environment that fosters continuous learning' 'evolving industry'\n",
            " 'expand my' 'expand my expertise' 'expand my expertise in'\n",
            " 'expand my expertise in deep' 'expertise in' 'expertise in deep'\n",
            " 'expertise in deep learning' 'expertise in deep learning and'\n",
            " 'exposure to' 'exposure to cutting' 'exposure to cutting edge'\n",
            " 'exposure to cutting edge technologies' 'fast evolving'\n",
            " 'fast evolving industry' 'field of' 'field of analytics'\n",
            " 'field of analytics and' 'field of analytics and ai' 'focused on'\n",
            " 'focused on career' 'focused on career advancement'\n",
            " 'focused on career advancement and' 'for leadership' 'for role'\n",
            " 'for role that' 'for role that offers' 'for role that offers broader'\n",
            " 'fosters continuous' 'fosters continuous learning'\n",
            " 'fosters continuous learning and' 'fosters continuous learning and skill'\n",
            " 'from dynamic' 'from dynamic team' 'from dynamic team of'\n",
            " 'from dynamic team of professionals' 'goal is' 'goal is to'\n",
            " 'goal is to secure' 'goal is to secure position' 'greater impact'\n",
            " 'greater impact in' 'greater impact in the' 'greater impact in the field'\n",
            " 'greater responsibilities' 'greater responsibilities and'\n",
            " 'greater responsibilities and opportunities'\n",
            " 'greater responsibilities and opportunities for' 'grow professionally'\n",
            " 'grow professionally and' 'grow professionally and make'\n",
            " 'grow professionally and make significant' 'impact in' 'impact in the'\n",
            " 'impact in the field' 'impact in the field of' 'in an'\n",
            " 'in an environment' 'in an environment that'\n",
            " 'in an environment that fosters' 'in deep' 'in deep learning'\n",
            " 'in deep learning and' 'in deep learning and large' 'in fast'\n",
            " 'in fast evolving' 'in fast evolving industry' 'in the' 'in the field'\n",
            " 'in the field of' 'in the field of analytics' 'innovative projects'\n",
            " 'interest and' 'interest and growth' 'is driven' 'is driven by'\n",
            " 'is driven by the' 'is driven by the desire' 'is to' 'is to secure'\n",
            " 'is to secure position' 'is to secure position with' 'language models'\n",
            " 'language models which' 'language models which are'\n",
            " 'language models which are areas' 'large language'\n",
            " 'large language models' 'large language models which'\n",
            " 'large language models which are' 'learn from' 'learn from dynamic'\n",
            " 'learn from dynamic team' 'learn from dynamic team of' 'learning and'\n",
            " 'learning and large' 'learning and large language'\n",
            " 'learning and large language models' 'learning and skill'\n",
            " 'learning and skill development' 'learning projects'\n",
            " 'learning projects that' 'learning projects that align'\n",
            " 'learning projects that align with' 'long term' 'long term professional'\n",
            " 'long term professional aspirations' 'looking for' 'looking for role'\n",
            " 'looking for role that' 'looking for role that offers' 'machine learning'\n",
            " 'machine learning projects' 'machine learning projects that'\n",
            " 'machine learning projects that align' 'make greater'\n",
            " 'make greater impact' 'make greater impact in'\n",
            " 'make greater impact in the' 'make significant'\n",
            " 'make significant contribution' 'make significant contribution in'\n",
            " 'make significant contribution in fast' 'me to' 'me to make'\n",
            " 'me to make greater' 'me to make greater impact' 'models which'\n",
            " 'models which are' 'models which are areas' 'models which are areas of'\n",
            " 'more challenging' 'more challenging roles' 'more challenging roles that'\n",
            " 'more challenging roles that allow' 'my career' 'my career goals'\n",
            " 'my decision' 'my decision is' 'my decision is driven'\n",
            " 'my decision is driven by' 'my expertise' 'my expertise in'\n",
            " 'my expertise in deep' 'my expertise in deep learning' 'my goal'\n",
            " 'my goal is' 'my goal is to' 'my goal is to secure' 'my personal'\n",
            " 'my personal values' 'my personal values and'\n",
            " 'my personal values and career' 'my work' 'my work with'\n",
            " 'my work with long' 'my work with long term' 'of an' 'of an organization'\n",
            " 'of an organization where' 'of an organization where can' 'of analytics'\n",
            " 'of analytics and' 'of analytics and ai' 'of personal'\n",
            " 'of personal interest' 'of personal interest and'\n",
            " 'of personal interest and growth' 'of professionals' 'offers better'\n",
            " 'offers better alignment' 'offers better alignment with'\n",
            " 'offers better alignment with my' 'offers broader'\n",
            " 'offers broader exposure' 'offers broader exposure to'\n",
            " 'offers broader exposure to cutting' 'on advanced' 'on advanced data'\n",
            " 'on advanced data science' 'on advanced data science and' 'on career'\n",
            " 'on career advancement' 'on career advancement and'\n",
            " 'on career advancement and aligning' 'on more' 'on more challenging'\n",
            " 'on more challenging roles' 'on more challenging roles that'\n",
            " 'opportunities for' 'opportunities for leadership' 'opportunities to'\n",
            " 'opportunities to work' 'opportunities to work on'\n",
            " 'opportunities to work on advanced' 'organization where'\n",
            " 'organization where can' 'organization where can contribute'\n",
            " 'organization where can contribute to' 'part of' 'part of an'\n",
            " 'part of an organization' 'part of an organization where'\n",
            " 'personal interest' 'personal interest and'\n",
            " 'personal interest and growth' 'personal values' 'personal values and'\n",
            " 'personal values and career' 'personal values and career vision'\n",
            " 'position with' 'position with greater'\n",
            " 'position with greater responsibilities'\n",
            " 'position with greater responsibilities and' 'professional aspirations'\n",
            " 'professionally and' 'professionally and make'\n",
            " 'professionally and make significant'\n",
            " 'professionally and make significant contribution' 'projects that'\n",
            " 'projects that align' 'projects that align with'\n",
            " 'projects that align with my' 'responsibilities and'\n",
            " 'responsibilities and opportunities'\n",
            " 'responsibilities and opportunities for'\n",
            " 'responsibilities and opportunities for leadership' 'role that'\n",
            " 'role that offers' 'role that offers better'\n",
            " 'role that offers better alignment' 'role that offers broader'\n",
            " 'role that offers broader exposure' 'roles that' 'roles that allow'\n",
            " 'roles that allow me' 'roles that allow me to' 'science and'\n",
            " 'science and machine' 'science and machine learning'\n",
            " 'science and machine learning projects' 'secure position'\n",
            " 'secure position with' 'secure position with greater'\n",
            " 'secure position with greater responsibilities' 'seeking opportunities'\n",
            " 'seeking opportunities to' 'seeking opportunities to work'\n",
            " 'seeking opportunities to work on' 'seeking role' 'seeking role that'\n",
            " 'seeking role that offers' 'seeking role that offers better'\n",
            " 'significant contribution' 'significant contribution in'\n",
            " 'significant contribution in fast'\n",
            " 'significant contribution in fast evolving' 'skill development' 'take on'\n",
            " 'take on more' 'take on more challenging'\n",
            " 'take on more challenging roles' 'team of' 'team of professionals'\n",
            " 'technologies and' 'technologies and innovative'\n",
            " 'technologies and innovative projects' 'term professional'\n",
            " 'term professional aspirations' 'that align' 'that align with'\n",
            " 'that align with my' 'that align with my career' 'that allow'\n",
            " 'that allow me' 'that allow me to' 'that allow me to make' 'that fosters'\n",
            " 'that fosters continuous' 'that fosters continuous learning'\n",
            " 'that fosters continuous learning and' 'that offers' 'that offers better'\n",
            " 'that offers better alignment' 'that offers better alignment with'\n",
            " 'that offers broader' 'that offers broader exposure'\n",
            " 'that offers broader exposure to' 'the desire' 'the desire to'\n",
            " 'the desire to grow' 'the desire to grow professionally' 'the field'\n",
            " 'the field of' 'the field of analytics' 'the field of analytics and'\n",
            " 'to and' 'to and learn' 'to and learn from' 'to and learn from dynamic'\n",
            " 'to be' 'to be part' 'to be part of' 'to be part of an' 'to cutting'\n",
            " 'to cutting edge' 'to cutting edge technologies'\n",
            " 'to cutting edge technologies and' 'to expand' 'to expand my'\n",
            " 'to expand my expertise' 'to expand my expertise in' 'to grow'\n",
            " 'to grow professionally' 'to grow professionally and'\n",
            " 'to grow professionally and make' 'to make' 'to make greater'\n",
            " 'to make greater impact' 'to make greater impact in' 'to secure'\n",
            " 'to secure position' 'to secure position with'\n",
            " 'to secure position with greater' 'to take' 'to take on'\n",
            " 'to take on more' 'to take on more challenging' 'to work' 'to work in'\n",
            " 'to work in an' 'to work in an environment' 'to work on'\n",
            " 'to work on advanced' 'to work on advanced data' 'values and'\n",
            " 'values and career' 'values and career vision' 'want to' 'want to take'\n",
            " 'want to take on' 'want to take on more' 'want to work' 'want to work in'\n",
            " 'want to work in an' 'where can' 'where can contribute'\n",
            " 'where can contribute to' 'where can contribute to and' 'which are'\n",
            " 'which are areas' 'which are areas of' 'which are areas of personal'\n",
            " 'with greater' 'with greater responsibilities'\n",
            " 'with greater responsibilities and'\n",
            " 'with greater responsibilities and opportunities' 'with long'\n",
            " 'with long term' 'with long term professional'\n",
            " 'with long term professional aspirations' 'with my' 'with my career'\n",
            " 'with my career goals' 'with my personal' 'with my personal values'\n",
            " 'with my personal values and' 'work in' 'work in an'\n",
            " 'work in an environment' 'work in an environment that' 'work on'\n",
            " 'work on advanced' 'work on advanced data'\n",
            " 'work on advanced data science' 'work with' 'work with long'\n",
            " 'work with long term' 'work with long term professional']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building TF-IDF vector\n",
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Generate matrix of word vectors\n",
        "tfidf_matrix = vectorizer.fit_transform(doc_list)\n",
        "print(tfidf_matrix.toarray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSyVJiKdh9FH",
        "outputId": "b335f7af-ff76-4e6d-a7b9-187170c5c090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method _cs_matrix.toarray of <10x104 sparse matrix of type '<class 'numpy.float64'>'\n",
            "\twith 161 stored elements in Compressed Sparse Row format>>\n"
          ]
        }
      ]
    }
  ]
}